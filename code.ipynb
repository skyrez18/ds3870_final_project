{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used Car Sale Auction Prices\n",
    "By Sky Reznik, John Lackey and Kevin Abatto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd; # type: ignore\n",
    "import numpy as np; # type: ignore\n",
    "from sklearn.preprocessing import OneHotEncoder; # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os;\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi; # type: ignore"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data using Kaggle KPI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Specify the dataset and the path to save it\n",
    "dataset_name = 'tunguz/used-car-auction-prices'  # Replace with your actual Kaggle dataset name\n",
    "download_path = './kaggle_datasets'     # Folder to store the dataset\n",
    "\n",
    "# Create download path if it doesn't exist\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)\n",
    "\n",
    "# Check if file exists\n",
    "dataset_file_path = os.path.join(download_path, 'car_prices.csv')   \n",
    "# Check if the dataset already exists in the folder\n",
    "if not os.path.exists(dataset_file_path):\n",
    "    # Initialize the Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()  # Authenticate using your Kaggle credentials\n",
    "\n",
    "    # Download the dataset\n",
    "    print(f\"Downloading {dataset_name}...\")\n",
    "    api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Dataset already exists, download skipped.\")\n",
    "\n",
    "# Load CSV into a pandas dataframe\n",
    "shared_file_path = './kaggle_datasets/car_prices.csv'\n",
    "# line 408,163 - \"Model\" field contains a comma (SE PZEV w/Connectivity, Navigation) - specify quotechar='\"'\n",
    "# This tells Pandas to treat anything inside double quotes as a single field, even if it contains commas.\n",
    "#      solution provided by ChatGPT\n",
    "df = pd.read_csv(shared_file_path, quotechar='\"', on_bad_lines='skip')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load datasets\n",
    "msrp = pd.read_csv('MSRP.csv')\n",
    "\n",
    "# Standardize column names and values\n",
    "msrp.rename(columns={\n",
    "    'Make': 'make',\n",
    "    \"Model\": \"model\",\n",
    "    \"Year\": \"year\",\n",
    "    \"Transmission Type\": \"transmission\"\n",
    "}, inplace=True)\n",
    "\n",
    "msrp['transmission'] = msrp['transmission'].str.lower()\n",
    "\n",
    "# Create matching keys\n",
    "df['match_key'] = (\n",
    "    df['year'].astype(str).str.lower() + '_' + \n",
    "    df['make'].str.lower() + '_' + \n",
    "    df['model'].str.lower() + '_' + \n",
    "    df['transmission'].str.lower()\n",
    ")\n",
    "\n",
    "msrp['match_key'] = (\n",
    "    msrp['year'].astype(str).str.lower() + '_' + \n",
    "    msrp['make'].str.lower() + '_' + \n",
    "    msrp['model'].str.lower() + '_' + \n",
    "    msrp['transmission'].str.lower()\n",
    ")\n",
    "\n",
    "# Sort by MSRP (ascending) and keep first (min) for each match_key\n",
    "msrp_min_row = msrp.sort_values('MSRP').drop_duplicates('match_key', keep='first')\n",
    "\n",
    "# Merge with original car data (keeping all car rows but adding MSRP where matched)\n",
    "car_with_msrp = df.merge(\n",
    "    msrp_min_row[['match_key', 'MSRP']],  # Only keep needed columns\n",
    "    on='match_key',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the temporary key column\n",
    "car_with_msrp = car_with_msrp.drop(columns=['match_key'])\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "car_with_msrp.to_csv('car_prices_with_msrp.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "__Done__\n",
    "1) Remove any row with missing data with df.dropna()\n",
    "2) One-Hot encode ['transmission'] to ['automatic_trans'] 0 /1 (double check unique vals)\n",
    "3) Simplify ['body'] (collapse all 85 body types to 9 types)\n",
    "4) Convert ['saledate']\n",
    "5) Age of car (from ['saledate'])\n",
    "6) Drop negative age cars\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# now we can use the car_prices_with_msrp DataFrame\n",
    "df = pd.read_csv('car_prices_with_msrp.csv', low_memory=False)\n",
    "# Remove 'Unamed: 16' column\n",
    "df.drop('Unnamed: 16', axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Remove rows that have missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.dropna(inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - One-hot encode the 'transmission' column\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(df['transmission'].unique())\n",
    "df['auto_transmission'] = np.where(df['transmission'].str.contains('automatic', case=False), 1, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - 'One-hot encode' the 'body' column (count 85 unique values --> reduce to 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ['suv' 'sedan' 'convertible' 'coupe' 'wagon' 'hatchback' 'truck' 'minivan' 'van']\n",
    "df['body_type'] = np.nan\n",
    "df['body_type'] = np.where(df['body'].str.contains('minivan', case=False), 'minivan', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('sedan', case=False), 'sedan', df['body'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('wagon', case=False), 'wagon', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('coupe', case=False), 'coupe', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('koup', case=False), 'coupe', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('convertible', case=False), 'convertible', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('hatchback', case=False), 'hatchback', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains(r'\\bvan\\b', case=False), 'van', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('truck', case=False), 'truck', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('cab', case=False), 'truck', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('crew', case=False), 'truck', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('suv', case=False), 'suv', df['body_type'])\n",
    "df['body_type'] = np.where(df['body'].str.contains('Minivan', case=False), 'minivan', df['body_type'])\n",
    "\n",
    "# Numerical mapping for body types\n",
    "size_mapping = {\n",
    "    'convertible': 0,\n",
    "    'coupe': 1,\n",
    "    'hatchback': 2,\n",
    "    'sedan': 3,\n",
    "    'wagon': 4,\n",
    "    'suv': 5,\n",
    "    'minivan': 6,\n",
    "    'truck': 7,\n",
    "    'van': 8\n",
    "}\n",
    "\n",
    "df['body_size'] = df['body_type'].map(size_mapping)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Converting 'saledate' to datetime (solution provided by ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Handle invalid or unexpected values in the 'saledate' column\n",
    "# Extract just the date part (e.g., \"Dec 16 2014\") before conversion\n",
    "df['saledate'] = pd.to_datetime(\n",
    "    df['saledate'].str.extract(r'(\\w{3} \\d{2} \\d{4})')[0], \n",
    "    format='%b %d %Y', \n",
    "    errors='coerce'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Ensure 'saledate' is in datetime format and create a new column 'car_age'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df['car_age'] = np.where(\n",
    "    df['saledate'].notna(),\n",
    "    df['saledate'].dt.year - df['year'],\n",
    "    np.nan\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Some car ages are negative, which is not possible, because a 2015 model year can exist in 2014 and subsequently be sold"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# For rows with values less than 0, drop rows\n",
    "print(\"Number of negative car ages: \", df[df['car_age'] < 0].shape[0])\n",
    "df.drop(df[df['car_age'] < 0].index, inplace=True)\n",
    "# Drop old columns 'transmission' & 'body'\n",
    "df.drop(['transmission', 'body'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vizualization\n",
    "Plot 'mmr' v. 'sellingprice'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ensure mmr and sellingprice are numeric\n",
    "df['mmr'] = pd.to_numeric(df['mmr'], errors='coerce')\n",
    "df['sellingprice'] = pd.to_numeric(df['sellingprice'], errors='coerce')\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.scatter(df['mmr'], df['sellingprice'], alpha=0.2, s=5) # Create a scatter plot\n",
    "sns.regplot(x='mmr', y='sellingprice', data=df, scatter=False, color='red') # Linear fit line\n",
    "plt.title('MMR vs Selling Price')\n",
    "plt.xlabel('MMR')\n",
    "plt.ylabel('Selling Price')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using features to predict selling price\n",
    "List of numeric features:\n",
    "1. year\n",
    "2. condition\n",
    "3. odometer\n",
    "4. auto_transmission\n",
    "5. car_age\n",
    "6. MSRP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_predictor = df[['year', 'condition', 'odometer', 'auto_transmission', 'car_age', 'MSRP']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X= df[['year', 'condition', 'odometer', 'auto_transmission', 'car_age', 'MSRP']]\n",
    "y = df['sellingprice']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=39)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = LinearRegression()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.fit(X_train, Y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "print(f\"R^2 (coefficient of determination): {r2}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions vs actual selling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(Y_test, y_pred, alpha=0.5, color='blue') \n",
    "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linewidth=1.5) # Perfect prediction line\n",
    "plt.xlabel('Actual Selling Price') \n",
    "plt.ylabel('Predicted Selling Price')\n",
    "plt.title('Actual vs Predicted Selling Price')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's learn more about our data now that is has been cleaned"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.head(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(df.make.unique())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.make.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize this data, there's alot of brands, so we'll only visualize the top 10 value counts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "top10 = df.make.value_counts().nlargest(10) # top 10\n",
    "top10.plot(kind=\"bar\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
